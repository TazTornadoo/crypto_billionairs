{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_storage import create_connection\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = create_connection(\"../database/crypto_billionairs.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train):\n",
    "    \n",
    "    clf = RandomForestClassifier(criterion=\"entropy\", min_samples_split= 0.01, min_samples_leaf= 0.005, max_depth=10, class_weight=\"balanced_subsample\")\n",
    "    print(\"training random forest!\")\n",
    "    clf.fit(X_train, y_train)\n",
    "   \n",
    "    return \"random_forest\", clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train, y_train):\n",
    "    \n",
    "    neigh = KNeighborsClassifier(weights=\"uniform\", n_neighbors=5, algorithm=\"ball_tree\")\n",
    "    print(\"training knn!\")\n",
    "    neigh.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    return \"knn\", neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machine(X_train, y_train):\n",
    "    \n",
    "    svc = SVC(kernel=\"poly\", degree=4, C=1)\n",
    "    print(\"training svc!\")\n",
    "    svc.fit(X_train, y_train)\n",
    "    \n",
    "    return \"support_vector_classifier\", svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(X_train, y_train):\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10), activation=\"tanh\", solver=\"lbfgs\", learning_rate=\"constant\", learning_rate_init=2e-5, tol=1e-5)\n",
    "    print(\"training mlp!\")\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    return \"mlp_classifier\", mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, y_train):\n",
    "    \n",
    "    lg = LogisticRegression(solver=\"liblinear\", penalty=\"l1\", C=1)\n",
    "    print(\"training lr!\")\n",
    "    lg.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    return \"logistic_regression\", lg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ensemble(rf_model, knn_model, mlp_model, lr_model, X_train, y_train):\n",
    "    \n",
    "    ensemble_dataset = pd.DataFrame(columns = range(12))\n",
    "    ensemble_dataset.columns = [\"rf_1\", \"rf_0\", \"rf_negative_1\", \"knn_1\", \"knn_0\", \"knn_negative_1\", \"mlp_1\", \"mlp_0\", \"mlp_negative_1\", \"lr_1\", \"lr_0\", \"lr_negative_1\"]\n",
    "        \n",
    "    rf_pred_proba = rf_model.predict_proba(X_train)\n",
    "    knn_pred_proba = knn_model.predict_proba(X_train)\n",
    "    mlp_pred_proba = mlp_model.predict_proba(X_train)\n",
    "    lr_pred_proba = lr_model.predict_proba(X_train)\n",
    "        \n",
    "    ensemble_dataset[\"rf_1\"] = rf_pred_proba[:, 0]\n",
    "    ensemble_dataset[\"rf_0\"] = rf_pred_proba[:, 1]\n",
    "    ensemble_dataset[\"rf_negative_1\"] = rf_pred_proba[:, 2]\n",
    "        \n",
    "    ensemble_dataset[\"knn_1\"] = knn_pred_proba[:, 0]\n",
    "    ensemble_dataset[\"knn_0\"] = knn_pred_proba[:, 1]\n",
    "    ensemble_dataset[\"knn_negative_1\"] = knn_pred_proba[:, 2]\n",
    "        \n",
    "    ensemble_dataset[\"mlp_1\"] = mlp_pred_proba[:, 0]\n",
    "    ensemble_dataset[\"mlp_0\"] = mlp_pred_proba[:, 1]\n",
    "    ensemble_dataset[\"mlp_negative_1\"] = mlp_pred_proba[:, 2]\n",
    "        \n",
    "    ensemble_dataset[\"lr_1\"] = lr_pred_proba[:, 0]\n",
    "    ensemble_dataset[\"lr_0\"] = lr_pred_proba[:, 1]\n",
    "    ensemble_dataset[\"lr_negative_1\"] = lr_pred_proba[:, 2]\n",
    "\n",
    "    \n",
    "    print(\"training ensemble!\")\n",
    "    \n",
    "    # mlp = MLPClassifier(hidden_layer_sizes=(10, 10), activation=\"tanh\", solver=\"lbfgs\", learning_rate=\"constant\", learning_rate_init=2e-5, tol=1e-5)\n",
    "    # mlp.fit(ensemble_dataset, y_train)\n",
    "    \n",
    "    clf_new = RandomForestClassifier(criterion=\"entropy\")\n",
    "    clf_new.fit(X_train, y_train)\n",
    "    \n",
    "    return \"ensemble\", clf_new\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(X_test, y_test, model, model_name, table, db_connection):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([X_test])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    \n",
    "    df.to_sql(f\"{table}_{model_name}_pooling\", db_connection, if_exists=\"replace\")\n",
    "    \n",
    "    return f\"{model_name}_pooling\", f1score, f1score_macro, recall, precision, y_pred_proba[:, 0], y_pred_proba[:, 1], y_pred_proba[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_ensemble(market_data, X_test, y_test, model, model_name, table, db_connection):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([market_data])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    \n",
    "    df.to_sql(f\"{table}_{model_name}_pooling\", db_connection, if_exists=\"replace\")\n",
    "    \n",
    "    return f\"{model_name}_pooling\", f1score, f1score_macro, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ml_algorithms_pooling(db_connection):\n",
    "    \n",
    "    df_temp = pd.read_sql_query(f\"select * from cryptocurrency_pooling_dataset\", db_connection)\n",
    "    df_temp = shuffle(df_temp, random_state=42069)\n",
    "    \n",
    "    y_train = df_temp[\"buy_indicator\"] + df_temp[\"short_indicator\"]\n",
    "    y_train = y_train.fillna(0)\n",
    "    y_train = y_train.astype(str)\n",
    "        \n",
    "    X_train = df_temp.drop([\"return\", \"buy_indicator\", \"short_indicator\",\"close_buy_indicator\", \"close_short_indicator\", \"time\", \"index\", \"level_0\"], axis=1)\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    rf_name, rf_model = random_forest(X_resampled, y_resampled)\n",
    "    knn_name, knn_model = knn(X_resampled, y_resampled)\n",
    "    #svc_name, svc_model = support_vector_machine(X_resampled, y_resampled)\n",
    "    mlp_name, mlp_model = mlp(X_resampled, y_resampled)\n",
    "    lr_name, lr_model = logistic_regression(X_resampled, y_resampled)\n",
    "    \n",
    "    ensemble_name, ensemble_model = model_ensemble(rf_model, knn_model, mlp_model, lr_model, X_train, y_train)\n",
    "    #creating the evaluation metric\n",
    "    df_ml = pd.DataFrame(columns = range(6))\n",
    "    df_ml.columns = [\"table_name\", \"model\", \"f1-score weighted\", \"f1-score macro\", \"recall macro\", \"precision macro\"]\n",
    "    \n",
    "    table_names = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\", db_connection)\n",
    "    \n",
    "    table_names_list = table_names['name'].tolist()\n",
    "\n",
    "    filtered_table_names = [name for name in table_names_list if \"_1day_features\" in name and 'trades' not in name and 'equity_curve' not in name and '_pooling' not in name]\n",
    "    print(filtered_table_names)\n",
    "    for table in filtered_table_names:\n",
    "        \n",
    "        df_temp = pd.read_sql_query(f\"select * from {table}\", db_connection)\n",
    "        y = df_temp[\"buy_indicator\"] + df_temp[\"short_indicator\"]\n",
    "        y = y.fillna(0)\n",
    "        y = y.astype(str)\n",
    "        X = df_temp.drop([\"return\", \"buy_indicator\", \"short_indicator\",\"close_buy_indicator\", \"close_short_indicator\", \"time\", \"index\"], axis=1)\n",
    "\n",
    "        X_test = X.iloc[-365:]\n",
    "        y_test = y.iloc[-365:]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision, rf_pred_class1, rf_pred_class0, rf_pred_class_negative_1 = evaluation(X_test, y_test, rf_model, rf_name, table, connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision, knn_pred_class1, knn_pred_class0, knn_pred_class_negative_1 = evaluation(X_test, y_test, knn_model, knn_name, table, connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        # string, score, f1score_macro, recall, precision = evaluation(X_test, y_test, svc_model, svc_name, table, connection)\n",
    "        # df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision, mlp_pred_class1, mlp_pred_class0, mlp_pred_class_negative_1 = evaluation(X_test, y_test, mlp_model, mlp_name, table, connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision, lr_pred_class1, lr_pred_class0, lr_pred_class_negative_1 = evaluation(X_test, y_test, lr_model, lr_name, table, connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        ensemble_dataset = pd.DataFrame(columns = range(12))\n",
    "        ensemble_dataset.columns = [\"rf_1\", \"rf_0\", \"rf_negative_1\", \"knn_1\", \"knn_0\", \"knn_negative_1\", \"mlp_1\", \"mlp_0\", \"mlp_negative_1\", \"lr_1\", \"lr_0\", \"lr_negative_1\"]\n",
    "        ensemble_dataset[\"rf_1\"] = rf_pred_class1\n",
    "        ensemble_dataset[\"rf_0\"] = rf_pred_class0\n",
    "        ensemble_dataset[\"rf_negative_1\"] = rf_pred_class_negative_1\n",
    "        \n",
    "        ensemble_dataset[\"knn_1\"] = knn_pred_class1\n",
    "        ensemble_dataset[\"knn_0\"] = knn_pred_class0\n",
    "        ensemble_dataset[\"knn_negative_1\"] = knn_pred_class_negative_1\n",
    "        \n",
    "        ensemble_dataset[\"mlp_1\"] = mlp_pred_class1\n",
    "        ensemble_dataset[\"mlp_0\"] = mlp_pred_class0\n",
    "        ensemble_dataset[\"mlp_negative_1\"] = mlp_pred_class_negative_1\n",
    "        \n",
    "        ensemble_dataset[\"lr_1\"] = lr_pred_class1\n",
    "        ensemble_dataset[\"lr_0\"] = lr_pred_class0\n",
    "        ensemble_dataset[\"lr_negative_1\"] = lr_pred_class_negative_1\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision = evaluation_ensemble(X_test, ensemble_dataset, y_test, ensemble_model, ensemble_name, table, connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "    return df_ml\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training random forest!\n",
      "training knn!\n",
      "training mlp!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training lr!\n",
      "training ensemble!\n",
      "['ADA_1min_complete_1day_preprocessed_1day_features', 'BCH_1min_complete_1day_preprocessed_1day_features', 'BTC_1min_complete_1day_preprocessed_1day_features', 'DOGE_1min_complete_1day_preprocessed_1day_features', 'ETH_1min_complete_1day_preprocessed_1day_features', 'LINK_1min_complete_1day_preprocessed_1day_features', 'LTC_1min_complete_1day_preprocessed_1day_features', 'TRX_1min_complete_1day_preprocessed_1day_features']\n",
      "[[0.13548467 0.55631022 0.30820511]\n",
      " [0.15838687 0.5428805  0.29873263]\n",
      " [0.18772939 0.5699501  0.24232051]\n",
      " ...\n",
      " [0.3043268  0.25538276 0.44029044]\n",
      " [0.3144043  0.26033842 0.42525728]\n",
      " [0.33884449 0.30855288 0.35260264]]\n",
      "[[0.  0.2 0.8]\n",
      " [0.  0.2 0.8]\n",
      " [0.  0.2 0.8]\n",
      " ...\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]]\n",
      "[[0.32129683 0.30896826 0.36973491]\n",
      " [0.32129683 0.30896826 0.36973491]\n",
      " [0.32129683 0.30896826 0.36973491]\n",
      " ...\n",
      " [0.38916849 0.27739336 0.33343815]\n",
      " [0.38916849 0.27739336 0.33343815]\n",
      " [0.38916849 0.27739336 0.33343815]]\n",
      "[[0.20704719 0.58392628 0.20902654]\n",
      " [0.20762064 0.60951639 0.18286296]\n",
      " [0.22444751 0.6191732  0.15637929]\n",
      " ...\n",
      " [0.45387651 0.18319435 0.36292914]\n",
      " [0.50482098 0.17783226 0.31734676]\n",
      " [0.55825708 0.20264571 0.23909721]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- knn_0\n",
      "- knn_1\n",
      "- knn_negative_1\n",
      "- lr_0\n",
      "- lr_1\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- adl\n",
      "- adx14\n",
      "- ao14\n",
      "- atrp14\n",
      "- close\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 12 features, but RandomForestClassifier is expecting 25 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0c627557235c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_ml_algorithms_pooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-4f464cff8734>\u001b[0m in \u001b[0;36mapply_ml_algorithms_pooling\u001b[1;34m(db_connection)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mensemble_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lr_negative_1\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_pred_class_negative_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1score_macro\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensemble_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensemble_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensemble_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0mdf_ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1score_macro\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-2aef84c7bbac>\u001b[0m in \u001b[0;36mevaluation_ensemble\u001b[1;34m(market_data, X_test, y_test, model, model_name, table, db_connection)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluation_ensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarket_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_connection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mf1score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"weighted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mf1score_macro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"macro\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janfa\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    830\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m         \"\"\"\n\u001b[1;32m--> 832\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janfa\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    872\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janfa\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    603\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[0;32m    604\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janfa\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janfa\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 12 features, but RandomForestClassifier is expecting 25 features as input."
     ]
    }
   ],
   "source": [
    "df_ml = apply_ml_algorithms_pooling(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>model</th>\n",
       "      <th>f1-score weighted</th>\n",
       "      <th>f1-score macro</th>\n",
       "      <th>recall macro</th>\n",
       "      <th>precision macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>random_forest_pooling</td>\n",
       "      <td>0.602278</td>\n",
       "      <td>0.420879</td>\n",
       "      <td>0.456236</td>\n",
       "      <td>0.423721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>knn_pooling</td>\n",
       "      <td>0.051253</td>\n",
       "      <td>0.127965</td>\n",
       "      <td>0.312343</td>\n",
       "      <td>0.083177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>mlp_classifier_pooling</td>\n",
       "      <td>0.045408</td>\n",
       "      <td>0.104690</td>\n",
       "      <td>0.315163</td>\n",
       "      <td>0.070403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>logistic_regression_pooling</td>\n",
       "      <td>0.365707</td>\n",
       "      <td>0.291234</td>\n",
       "      <td>0.421558</td>\n",
       "      <td>0.419785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>ensemble_pooling</td>\n",
       "      <td>0.632125</td>\n",
       "      <td>0.380488</td>\n",
       "      <td>0.376806</td>\n",
       "      <td>0.409230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BCH_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>random_forest_pooling</td>\n",
       "      <td>0.562450</td>\n",
       "      <td>0.388222</td>\n",
       "      <td>0.455083</td>\n",
       "      <td>0.396363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BCH_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>knn_pooling</td>\n",
       "      <td>0.147135</td>\n",
       "      <td>0.174320</td>\n",
       "      <td>0.365642</td>\n",
       "      <td>0.449029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BCH_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>mlp_classifier_pooling</td>\n",
       "      <td>0.689792</td>\n",
       "      <td>0.384725</td>\n",
       "      <td>0.377463</td>\n",
       "      <td>0.454608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BCH_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>logistic_regression_pooling</td>\n",
       "      <td>0.575483</td>\n",
       "      <td>0.372043</td>\n",
       "      <td>0.404649</td>\n",
       "      <td>0.376522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BCH_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>ensemble_pooling</td>\n",
       "      <td>0.640825</td>\n",
       "      <td>0.383473</td>\n",
       "      <td>0.383373</td>\n",
       "      <td>0.448388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BTC_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>random_forest_pooling</td>\n",
       "      <td>0.494546</td>\n",
       "      <td>0.335527</td>\n",
       "      <td>0.388229</td>\n",
       "      <td>0.364863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BTC_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>knn_pooling</td>\n",
       "      <td>0.366270</td>\n",
       "      <td>0.249998</td>\n",
       "      <td>0.315123</td>\n",
       "      <td>0.328381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BTC_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>mlp_classifier_pooling</td>\n",
       "      <td>0.309461</td>\n",
       "      <td>0.254642</td>\n",
       "      <td>0.380098</td>\n",
       "      <td>0.355411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BTC_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>logistic_regression_pooling</td>\n",
       "      <td>0.576702</td>\n",
       "      <td>0.349485</td>\n",
       "      <td>0.356971</td>\n",
       "      <td>0.349398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BTC_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>ensemble_pooling</td>\n",
       "      <td>0.623953</td>\n",
       "      <td>0.359804</td>\n",
       "      <td>0.365502</td>\n",
       "      <td>0.358534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DOGE_1min_complete_1day_preprocessed_1day_feat...</td>\n",
       "      <td>random_forest_pooling</td>\n",
       "      <td>0.644882</td>\n",
       "      <td>0.394226</td>\n",
       "      <td>0.414195</td>\n",
       "      <td>0.391860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DOGE_1min_complete_1day_preprocessed_1day_feat...</td>\n",
       "      <td>knn_pooling</td>\n",
       "      <td>0.696451</td>\n",
       "      <td>0.317211</td>\n",
       "      <td>0.343726</td>\n",
       "      <td>0.395370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DOGE_1min_complete_1day_preprocessed_1day_feat...</td>\n",
       "      <td>mlp_classifier_pooling</td>\n",
       "      <td>0.013399</td>\n",
       "      <td>0.052587</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.028545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DOGE_1min_complete_1day_preprocessed_1day_feat...</td>\n",
       "      <td>logistic_regression_pooling</td>\n",
       "      <td>0.682381</td>\n",
       "      <td>0.313732</td>\n",
       "      <td>0.334353</td>\n",
       "      <td>0.305661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DOGE_1min_complete_1day_preprocessed_1day_feat...</td>\n",
       "      <td>ensemble_pooling</td>\n",
       "      <td>0.696451</td>\n",
       "      <td>0.317211</td>\n",
       "      <td>0.343726</td>\n",
       "      <td>0.395370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ETH_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>random_forest_pooling</td>\n",
       "      <td>0.418572</td>\n",
       "      <td>0.330050</td>\n",
       "      <td>0.423649</td>\n",
       "      <td>0.375604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ETH_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>knn_pooling</td>\n",
       "      <td>0.457983</td>\n",
       "      <td>0.308319</td>\n",
       "      <td>0.331618</td>\n",
       "      <td>0.331004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ETH_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>mlp_classifier_pooling</td>\n",
       "      <td>0.432085</td>\n",
       "      <td>0.335912</td>\n",
       "      <td>0.381928</td>\n",
       "      <td>0.393449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ETH_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>logistic_regression_pooling</td>\n",
       "      <td>0.545209</td>\n",
       "      <td>0.379533</td>\n",
       "      <td>0.427450</td>\n",
       "      <td>0.391753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ETH_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>ensemble_pooling</td>\n",
       "      <td>0.600633</td>\n",
       "      <td>0.349735</td>\n",
       "      <td>0.349881</td>\n",
       "      <td>0.359904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LINK_1min_complete_1day_preprocessed_1day_feat...</td>\n",
       "      <td>random_forest_pooling</td>\n",
       "      <td>0.540405</td>\n",
       "      <td>0.404382</td>\n",
       "      <td>0.452331</td>\n",
       "      <td>0.410435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LINK_1min_complete_1day_preprocessed_1day_feat...</td>\n",
       "      <td>knn_pooling</td>\n",
       "      <td>0.284024</td>\n",
       "      <td>0.215183</td>\n",
       "      <td>0.278429</td>\n",
       "      <td>0.311211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LINK_1min_complete_1day_preprocessed_1day_feat...</td>\n",
       "      <td>mlp_classifier_pooling</td>\n",
       "      <td>0.313541</td>\n",
       "      <td>0.240701</td>\n",
       "      <td>0.305467</td>\n",
       "      <td>0.319950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LINK_1min_complete_1day_preprocessed_1day_feat...</td>\n",
       "      <td>logistic_regression_pooling</td>\n",
       "      <td>0.557185</td>\n",
       "      <td>0.404187</td>\n",
       "      <td>0.447504</td>\n",
       "      <td>0.409774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LINK_1min_complete_1day_preprocessed_1day_feat...</td>\n",
       "      <td>ensemble_pooling</td>\n",
       "      <td>0.608069</td>\n",
       "      <td>0.358215</td>\n",
       "      <td>0.358393</td>\n",
       "      <td>0.381363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LTC_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>random_forest_pooling</td>\n",
       "      <td>0.500547</td>\n",
       "      <td>0.390131</td>\n",
       "      <td>0.477611</td>\n",
       "      <td>0.414618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LTC_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>knn_pooling</td>\n",
       "      <td>0.481382</td>\n",
       "      <td>0.276265</td>\n",
       "      <td>0.353668</td>\n",
       "      <td>0.296647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LTC_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>mlp_classifier_pooling</td>\n",
       "      <td>0.024832</td>\n",
       "      <td>0.070261</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.039269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LTC_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>logistic_regression_pooling</td>\n",
       "      <td>0.585933</td>\n",
       "      <td>0.396866</td>\n",
       "      <td>0.410359</td>\n",
       "      <td>0.395308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LTC_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>ensemble_pooling</td>\n",
       "      <td>0.635575</td>\n",
       "      <td>0.358501</td>\n",
       "      <td>0.383490</td>\n",
       "      <td>0.340090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>random_forest_pooling</td>\n",
       "      <td>0.617043</td>\n",
       "      <td>0.382276</td>\n",
       "      <td>0.409380</td>\n",
       "      <td>0.382354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>knn_pooling</td>\n",
       "      <td>0.677228</td>\n",
       "      <td>0.291152</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.258447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>mlp_classifier_pooling</td>\n",
       "      <td>0.035133</td>\n",
       "      <td>0.101707</td>\n",
       "      <td>0.287440</td>\n",
       "      <td>0.067066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>logistic_regression_pooling</td>\n",
       "      <td>0.387918</td>\n",
       "      <td>0.236105</td>\n",
       "      <td>0.380192</td>\n",
       "      <td>0.333974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>ensemble_pooling</td>\n",
       "      <td>0.677228</td>\n",
       "      <td>0.291152</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.258447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           table_name  \\\n",
       "0   ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "1   ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "2   ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "3   ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "4   ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "5   BCH_1min_complete_1day_preprocessed_1day_features   \n",
       "6   BCH_1min_complete_1day_preprocessed_1day_features   \n",
       "7   BCH_1min_complete_1day_preprocessed_1day_features   \n",
       "8   BCH_1min_complete_1day_preprocessed_1day_features   \n",
       "9   BCH_1min_complete_1day_preprocessed_1day_features   \n",
       "10  BTC_1min_complete_1day_preprocessed_1day_features   \n",
       "11  BTC_1min_complete_1day_preprocessed_1day_features   \n",
       "12  BTC_1min_complete_1day_preprocessed_1day_features   \n",
       "13  BTC_1min_complete_1day_preprocessed_1day_features   \n",
       "14  BTC_1min_complete_1day_preprocessed_1day_features   \n",
       "15  DOGE_1min_complete_1day_preprocessed_1day_feat...   \n",
       "16  DOGE_1min_complete_1day_preprocessed_1day_feat...   \n",
       "17  DOGE_1min_complete_1day_preprocessed_1day_feat...   \n",
       "18  DOGE_1min_complete_1day_preprocessed_1day_feat...   \n",
       "19  DOGE_1min_complete_1day_preprocessed_1day_feat...   \n",
       "20  ETH_1min_complete_1day_preprocessed_1day_features   \n",
       "21  ETH_1min_complete_1day_preprocessed_1day_features   \n",
       "22  ETH_1min_complete_1day_preprocessed_1day_features   \n",
       "23  ETH_1min_complete_1day_preprocessed_1day_features   \n",
       "24  ETH_1min_complete_1day_preprocessed_1day_features   \n",
       "25  LINK_1min_complete_1day_preprocessed_1day_feat...   \n",
       "26  LINK_1min_complete_1day_preprocessed_1day_feat...   \n",
       "27  LINK_1min_complete_1day_preprocessed_1day_feat...   \n",
       "28  LINK_1min_complete_1day_preprocessed_1day_feat...   \n",
       "29  LINK_1min_complete_1day_preprocessed_1day_feat...   \n",
       "30  LTC_1min_complete_1day_preprocessed_1day_features   \n",
       "31  LTC_1min_complete_1day_preprocessed_1day_features   \n",
       "32  LTC_1min_complete_1day_preprocessed_1day_features   \n",
       "33  LTC_1min_complete_1day_preprocessed_1day_features   \n",
       "34  LTC_1min_complete_1day_preprocessed_1day_features   \n",
       "35  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "36  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "37  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "38  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "39  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "\n",
       "                          model  f1-score weighted  f1-score macro  \\\n",
       "0         random_forest_pooling           0.602278        0.420879   \n",
       "1                   knn_pooling           0.051253        0.127965   \n",
       "2        mlp_classifier_pooling           0.045408        0.104690   \n",
       "3   logistic_regression_pooling           0.365707        0.291234   \n",
       "4              ensemble_pooling           0.632125        0.380488   \n",
       "5         random_forest_pooling           0.562450        0.388222   \n",
       "6                   knn_pooling           0.147135        0.174320   \n",
       "7        mlp_classifier_pooling           0.689792        0.384725   \n",
       "8   logistic_regression_pooling           0.575483        0.372043   \n",
       "9              ensemble_pooling           0.640825        0.383473   \n",
       "10        random_forest_pooling           0.494546        0.335527   \n",
       "11                  knn_pooling           0.366270        0.249998   \n",
       "12       mlp_classifier_pooling           0.309461        0.254642   \n",
       "13  logistic_regression_pooling           0.576702        0.349485   \n",
       "14             ensemble_pooling           0.623953        0.359804   \n",
       "15        random_forest_pooling           0.644882        0.394226   \n",
       "16                  knn_pooling           0.696451        0.317211   \n",
       "17       mlp_classifier_pooling           0.013399        0.052587   \n",
       "18  logistic_regression_pooling           0.682381        0.313732   \n",
       "19             ensemble_pooling           0.696451        0.317211   \n",
       "20        random_forest_pooling           0.418572        0.330050   \n",
       "21                  knn_pooling           0.457983        0.308319   \n",
       "22       mlp_classifier_pooling           0.432085        0.335912   \n",
       "23  logistic_regression_pooling           0.545209        0.379533   \n",
       "24             ensemble_pooling           0.600633        0.349735   \n",
       "25        random_forest_pooling           0.540405        0.404382   \n",
       "26                  knn_pooling           0.284024        0.215183   \n",
       "27       mlp_classifier_pooling           0.313541        0.240701   \n",
       "28  logistic_regression_pooling           0.557185        0.404187   \n",
       "29             ensemble_pooling           0.608069        0.358215   \n",
       "30        random_forest_pooling           0.500547        0.390131   \n",
       "31                  knn_pooling           0.481382        0.276265   \n",
       "32       mlp_classifier_pooling           0.024832        0.070261   \n",
       "33  logistic_regression_pooling           0.585933        0.396866   \n",
       "34             ensemble_pooling           0.635575        0.358501   \n",
       "35        random_forest_pooling           0.617043        0.382276   \n",
       "36                  knn_pooling           0.677228        0.291152   \n",
       "37       mlp_classifier_pooling           0.035133        0.101707   \n",
       "38  logistic_regression_pooling           0.387918        0.236105   \n",
       "39             ensemble_pooling           0.677228        0.291152   \n",
       "\n",
       "    recall macro  precision macro  \n",
       "0       0.456236         0.423721  \n",
       "1       0.312343         0.083177  \n",
       "2       0.315163         0.070403  \n",
       "3       0.421558         0.419785  \n",
       "4       0.376806         0.409230  \n",
       "5       0.455083         0.396363  \n",
       "6       0.365642         0.449029  \n",
       "7       0.377463         0.454608  \n",
       "8       0.404649         0.376522  \n",
       "9       0.383373         0.448388  \n",
       "10      0.388229         0.364863  \n",
       "11      0.315123         0.328381  \n",
       "12      0.380098         0.355411  \n",
       "13      0.356971         0.349398  \n",
       "14      0.365502         0.358534  \n",
       "15      0.414195         0.391860  \n",
       "16      0.343726         0.395370  \n",
       "17      0.333333         0.028545  \n",
       "18      0.334353         0.305661  \n",
       "19      0.343726         0.395370  \n",
       "20      0.423649         0.375604  \n",
       "21      0.331618         0.331004  \n",
       "22      0.381928         0.393449  \n",
       "23      0.427450         0.391753  \n",
       "24      0.349881         0.359904  \n",
       "25      0.452331         0.410435  \n",
       "26      0.278429         0.311211  \n",
       "27      0.305467         0.319950  \n",
       "28      0.447504         0.409774  \n",
       "29      0.358393         0.381363  \n",
       "30      0.477611         0.414618  \n",
       "31      0.353668         0.296647  \n",
       "32      0.333333         0.039269  \n",
       "33      0.410359         0.395308  \n",
       "34      0.383490         0.340090  \n",
       "35      0.409380         0.382354  \n",
       "36      0.333333         0.258447  \n",
       "37      0.287440         0.067066  \n",
       "38      0.380192         0.333974  \n",
       "39      0.333333         0.258447  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf7c0b8ed4c815043e48994c1e64c08f9d96fdc49c73ce762547f36d7ce0a11b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
