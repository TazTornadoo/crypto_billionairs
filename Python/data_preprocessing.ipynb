{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_storage import create_connection\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from stockstats import StockDataFrame\n",
    "import os\n",
    "import ta\n",
    "from pyti.chande_momentum_oscillator import chande_momentum_oscillator\n",
    "from pyti.accumulation_distribution import accumulation_distribution\n",
    "from pyti.average_true_range_percent import average_true_range_percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = create_connection(\"../database/crypto_billionairs.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load data into database\n",
    "def load_data_into_database(path, db_connection, header_list):\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "            \n",
    "            if file[-3:] == 'txt':\n",
    "                file_name = str(file).replace(\"-\", \"_\")\n",
    "                df = pd.read_csv(f'./{path}/{file}', names = header_list)\n",
    "                \n",
    "                df.to_sql(f'{file_name[:-4]}_complete_raw', con=db_connection, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "load_data_into_database(\"../database/\", connection, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data_1min(db_connection):\n",
    "    \n",
    "    table_names = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\", db_connection)\n",
    "    \n",
    "    table_names_list = table_names['name'].tolist()\n",
    "\n",
    "    filtered_table_names = [name for name in table_names_list if \"_complete_raw\" in name and 'trades' not in name]\n",
    "    \n",
    "    for table in filtered_table_names:\n",
    "        \n",
    "        df_temp = pd.read_sql_query(f\"select * from {table}\", db_connection)\n",
    "        \n",
    "        df_temp[\"time\"] = pd.to_datetime(df_temp['time'])\n",
    "        df_temp = df_temp.set_index('time')\n",
    "        \n",
    "        df_temp = df_temp.resample('1T').mean()\n",
    "        \n",
    "        df_temp[\"volume\"] = df_temp[\"volume\"].fillna(0)\n",
    "        df_temp[\"close\"] = df_temp[\"close\"].fillna(method=\"ffill\")\n",
    "        df_temp = df_temp.fillna(axis=1, method=\"backfill\")\n",
    "        #df_temp[\"time\"] = df_temp.index\n",
    "    \n",
    "        df_temp.to_sql(f\"{table[:-4]}_1min_preprocessed\", db_connection, if_exists=\"replace\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing_data_1min(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data_1day(db_connection):\n",
    "    \n",
    "    table_names = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\", db_connection)\n",
    "    \n",
    "    table_names_list = table_names['name'].tolist()\n",
    "\n",
    "    filtered_table_names = [name for name in table_names_list if \"_complete_raw\" in name and 'trades' not in name]\n",
    "    print(filtered_table_names)\n",
    "    for table in filtered_table_names:\n",
    "        \n",
    "        df_temp = pd.read_sql_query(f\"select * from {table}\", db_connection)\n",
    "        \n",
    "        df_temp[\"time\"] = pd.to_datetime(df_temp['time'])\n",
    "        df_temp = df_temp.set_index('time')\n",
    "        \n",
    "        df_temp = df_temp.resample('1D').mean()\n",
    "        \n",
    "        df_temp[\"volume\"] = df_temp[\"volume\"].fillna(0)\n",
    "        df_temp[\"close\"] = df_temp[\"close\"].fillna(method=\"ffill\")\n",
    "        df_temp = df_temp.fillna(axis=1, method=\"backfill\")\n",
    "      \n",
    "    \n",
    "        df_temp.to_sql(f\"{table[:-4]}_1day_preprocessed\", db_connection, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADA_1min_complete_raw', 'BCH_1min_complete_raw', 'BTC_1min_complete_raw', 'DOGE_1min_complete_raw', 'ETH_1min_complete_raw', 'LINK_1min_complete_raw', 'LTC_1min_complete_raw', 'TRX_1min_complete_raw']\n"
     ]
    }
   ],
   "source": [
    "preprocessing_data_1day(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def momentum2(df):\n",
    "#     df[\"return\"] = df[\"open\"] / df[\"close\"] - 1\n",
    "#     return df[\"return\"]\n",
    "\n",
    "def momentum(df, lag):\n",
    "    return df.pct_change(periods=lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_variable(df_target):\n",
    "    \n",
    "    df_target['return'] = momentum(df_target[\"close\"], 1)\n",
    "        \n",
    "    df_target[\"mean_return\"] = df_target[\"return\"].rolling(50).mean()\n",
    "        \n",
    "    df_target[\"std_deviation\"] = df_target[\"return\"].rolling(50).std()\n",
    "        \n",
    "    df_target[\"buy_indicator\"] = 0\n",
    "    df_target.loc[df_target[\"return\"] > df_target[\"mean_return\"] + 1 * df_target[\"std_deviation\"], 'buy_indicator'] = 1\n",
    "    df_target[\"buy_indicator\"] = df_target[\"buy_indicator\"].shift(-1)\n",
    "    df_target[\"close_buy_indicator\"] = df_target[\"buy_indicator\"].shift(1)\n",
    "        \n",
    "        \n",
    "    df_target[\"short_indicator\"] = 0\n",
    "    df_target.loc[df_target[\"return\"] < df_target[\"mean_return\"] - 1 * df_target[\"std_deviation\"], 'short_indicator'] = -1\n",
    "    df_target[\"short_indicator\"] = df_target[\"short_indicator\"].shift(-1)\n",
    "    df_target[\"close_short_indicator\"] = df_target[\"short_indicator\"].shift(1).fillna(0)\n",
    "    \n",
    "    return df_target[\"buy_indicator\"], df_target[\"short_indicator\"], df_target[\"close_buy_indicator\"], df_target[\"close_short_indicator\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_features(db_connection):\n",
    "    \n",
    "    table_names = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\", db_connection)\n",
    "    \n",
    "    table_names_list = table_names['name'].tolist()\n",
    "\n",
    "    filtered_table_names = [name for name in table_names_list if \"_1day_preprocessed\" in name and 'trades' not in name and \"_features\" not in name]\n",
    "    for table in filtered_table_names:\n",
    "        \n",
    "        df_temp = pd.read_sql_query(f\"select * from {table}\", db_connection)\n",
    "        \n",
    "        df_ti = pd.DataFrame()\n",
    "        df_ti[\"time\"] = df_temp[\"time\"]\n",
    "        df_ti[\"open\"] = df_temp[\"open\"]\n",
    "        df_ti[\"close\"] = df_temp[\"close\"]\n",
    "        df_ti[\"high\"] = df_temp[\"high\"]\n",
    "        df_ti[\"low\"] = df_temp[\"low\"]\n",
    "        df_ti[\"volume\"] = df_temp[\"volume\"]\n",
    "    \n",
    "        stock = StockDataFrame.retype(df_ti)\n",
    "        \n",
    "        df_temp[\"sma5-20\"] = stock.get(\"close_5_sma\") - stock.get(\"close_20_sma\")\n",
    "        df_temp[\"sma8-15\"] = stock.get(\"close_8_sma\") - stock.get(\"close_15_sma\")\n",
    "        df_temp[\"sma20-50\"] = stock.get(\"close_20_sma\") - stock.get(\"close_50_sma\")\n",
    "        df_temp[\"ema5-20\"] = stock.get(\"close_5_ema\") - stock.get(\"close_20_ema\")\n",
    "        df_temp[\"sma8-15\"] = stock.get(\"close_8_ema\") - stock.get(\"close_15_ema\")\n",
    "        df_temp[\"sma20-50\"] = stock.get(\"close_20_ema\") - stock.get(\"close_50_ema\")\n",
    "        df_temp[\"macd\"] = stock.get(\"macd\")\n",
    "        df_temp[\"ao14\"] = ta.trend.AroonIndicator(df_temp[\"close\"], window = 14, fillna=True).aroon_indicator() \n",
    "        df_temp[\"adx14\"] = ta.trend.ADXIndicator(df_temp[\"high\"], df_temp[\"low\"], df_temp[\"close\"], 14).adx()\n",
    "        df_temp[\"wd14\"] = stock.get(\"pdi_14\") - stock.get(\"mdi_14\")\n",
    "        \n",
    "        df_temp[\"ppo12-26\"] = stock.get(\"ppo\") #default is 14\n",
    "        df_temp[\"rsi14\"] = stock.get(\"rsi_14\")\n",
    "        df_temp[\"mfi14\"] = stock.get(\"mfi_14\")\n",
    "        df_temp[\"tsi\"] = ta.momentum.TSIIndicator(df_temp[\"close\"], fillna=True).tsi()\n",
    "        df_temp[\"so14\"] = stock.get(\"kdjk_14\")\n",
    "        df_temp[\"cmo14\"] = chande_momentum_oscillator(df_temp[\"close\"], 14)\n",
    "        df_temp[\"atrp14\"] = average_true_range_percent(df_temp[\"close\"], 14)\n",
    "        \n",
    "        df_temp[\"pvo12-26\"] = ta.momentum.PercentageVolumeOscillator(df_temp[\"volume\"], fillna=True).pvo()\n",
    "        df_temp[\"adl\"] = accumulation_distribution(df_temp[\"close\"], df_temp[\"high\"], df_temp[\"low\"], df_temp[\"volume\"])\n",
    "        df_temp[\"obv\"] = ta.volume.OnBalanceVolumeIndicator(df_temp[\"close\"], df_temp[\"volume\"]).on_balance_volume()\n",
    "        df_temp[\"fi13\"] = ta.volume.ForceIndexIndicator(df_temp[\"close\"], df_temp[\"volume\"], 13, fillna= True).force_index()\n",
    "        df_temp[\"fi50\"] = ta.volume.ForceIndexIndicator(df_temp[\"close\"], df_temp[\"volume\"], 50, fillna=True).force_index()\n",
    "        \n",
    "        df_temp = df_temp.fillna(method = \"backfill\")\n",
    "        df_temp = df_temp.fillna(method =\"ffill\")\n",
    "        \n",
    "        df_temp[\"buy_indicator\"], df_temp[\"short_indicator\"], df_temp[\"close_buy_indicator\"], df_temp[\"close_short_indicator\"] = create_target_variable(df_temp)\n",
    "        df_temp = df_temp.drop(['mean_return', 'std_deviation'], axis=1)\n",
    "        df_temp.to_sql(f\"{table}_1day_features\", db_connection, if_exists=\"replace\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pyti\\accumulation_distribution.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (((close_data[idx] - low_data[idx]) -\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pyti\\accumulation_distribution.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (((close_data[idx] - low_data[idx]) -\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pyti\\accumulation_distribution.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (((close_data[idx] - low_data[idx]) -\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pyti\\accumulation_distribution.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (((close_data[idx] - low_data[idx]) -\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pyti\\accumulation_distribution.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (((close_data[idx] - low_data[idx]) -\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pyti\\accumulation_distribution.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (((close_data[idx] - low_data[idx]) -\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pyti\\accumulation_distribution.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (((close_data[idx] - low_data[idx]) -\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\ta\\trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "c:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pyti\\accumulation_distribution.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (((close_data[idx] - low_data[idx]) -\n"
     ]
    }
   ],
   "source": [
    "create_features(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pooling_dataset(db_connection):\n",
    "    \n",
    "    table_names = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\", db_connection)\n",
    "    \n",
    "    table_names_list = table_names['name'].tolist()\n",
    "\n",
    "    filtered_table_names = [name for name in table_names_list if \"_1day_features\" in name and 'trades' not in name and 'equity_curve' not in name]\n",
    "    print(filtered_table_names)\n",
    "    union_all_sql_list = []\n",
    "    \n",
    "    for table in filtered_table_names[:-1]:\n",
    "        \n",
    "        union_new_table = f\"SELECT * FROM {table } where time < '2021-04-01 00:00:00' UNION ALL\"\n",
    "        union_all_sql_list.append(union_new_table)\n",
    "    \n",
    "    union_all_sql_list.append(f\"SELECT * from {filtered_table_names[-1]} where time < '2021-04-01 00:00:00'\")\n",
    "\n",
    "    union_all_sql = ' '.join(union_all_sql_list)\n",
    "    \n",
    "    df = pd.read_sql_query(union_all_sql, db_connection)\n",
    "    print(len(df)) #11973 #7720\n",
    "\n",
    "    df.to_sql(\"cryptocurrency_pooling_dataset\", db_connection, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADA_1min_complete_1day_preprocessed_1day_features', 'BCH_1min_complete_1day_preprocessed_1day_features', 'BTC_1min_complete_1day_preprocessed_1day_features', 'BTC_1min_complete_1day_preprocessed_1day_features_knn_pooling', 'BTC_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling', 'BTC_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling', 'BTC_1min_complete_1day_preprocessed_1day_features_random_forest_pooling', 'DOGE_1min_complete_1day_preprocessed_1day_features', 'DOGE_1min_complete_1day_preprocessed_1day_features_knn_pooling', 'DOGE_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling', 'DOGE_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling', 'DOGE_1min_complete_1day_preprocessed_1day_features_random_forest_pooling', 'ETH_1min_complete_1day_preprocessed_1day_features', 'ETH_1min_complete_1day_preprocessed_1day_features_knn_pooling', 'ETH_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling', 'ETH_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling', 'ETH_1min_complete_1day_preprocessed_1day_features_random_forest_pooling', 'LINK_1min_complete_1day_preprocessed_1day_features', 'LTC_1min_complete_1day_preprocessed_1day_features', 'LTC_1min_complete_1day_preprocessed_1day_features_knn_pooling', 'LTC_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling', 'LTC_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling', 'LTC_1min_complete_1day_preprocessed_1day_features_random_forest_pooling', 'TRX_1min_complete_1day_preprocessed_1day_features']\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM ADA_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BCH_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BTC_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BTC_1min_complete_1day_preprocessed_1day_features_knn_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BTC_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BTC_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BTC_1min_complete_1day_preprocessed_1day_features_random_forest_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM DOGE_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM DOGE_1min_complete_1day_preprocessed_1day_features_knn_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM DOGE_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM DOGE_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM DOGE_1min_complete_1day_preprocessed_1day_features_random_forest_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM ETH_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM ETH_1min_complete_1day_preprocessed_1day_features_knn_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM ETH_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM ETH_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM ETH_1min_complete_1day_preprocessed_1day_features_random_forest_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LINK_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LTC_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LTC_1min_complete_1day_preprocessed_1day_features_knn_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LTC_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LTC_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LTC_1min_complete_1day_preprocessed_1day_features_random_forest_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * from TRX_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00'': no such column: time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1585\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1586\u001b[1;33m             \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1587\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such column: time",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-17eb23424752>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate_pooling_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-71-54f2f019f847>\u001b[0m in \u001b[0;36mcreate_pooling_dataset\u001b[1;34m(db_connection)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0munion_all_sql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munion_all_sql_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munion_all_sql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb_connection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#11973 #7720\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \"\"\"\n\u001b[0;32m    325\u001b[0m     \u001b[0mpandas_sql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m     return pandas_sql.read_query(\n\u001b[0m\u001b[0;32m    327\u001b[0m         \u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[0;32m   1631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1633\u001b[1;33m         \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1634\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\janfa\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m             \u001b[0mex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Execution failed on sql '{args[0]}': {exc}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM ADA_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BCH_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BTC_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BTC_1min_complete_1day_preprocessed_1day_features_knn_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BTC_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BTC_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM BTC_1min_complete_1day_preprocessed_1day_features_random_forest_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM DOGE_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM DOGE_1min_complete_1day_preprocessed_1day_features_knn_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM DOGE_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM DOGE_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM DOGE_1min_complete_1day_preprocessed_1day_features_random_forest_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM ETH_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM ETH_1min_complete_1day_preprocessed_1day_features_knn_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM ETH_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM ETH_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM ETH_1min_complete_1day_preprocessed_1day_features_random_forest_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LINK_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LTC_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LTC_1min_complete_1day_preprocessed_1day_features_knn_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LTC_1min_complete_1day_preprocessed_1day_features_logistic_regression_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LTC_1min_complete_1day_preprocessed_1day_features_mlp_classifier_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * FROM LTC_1min_complete_1day_preprocessed_1day_features_random_forest_pooling where time < '2021-04-01 00:00:00' UNION ALL SELECT * from TRX_1min_complete_1day_preprocessed_1day_features where time < '2021-04-01 00:00:00'': no such column: time"
     ]
    }
   ],
   "source": [
    "create_pooling_dataset(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf7c0b8ed4c815043e48994c1e64c08f9d96fdc49c73ce762547f36d7ce0a11b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
