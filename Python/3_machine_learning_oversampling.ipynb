{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_storage import create_connection\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook trains each machine learning model for each cryptocurrency and is evaluated in the end by \n",
    "#weighted F1 score, the macro F1 score, the macro recall and the macro precision\n",
    "#however the models are trained on an oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = create_connection(\"../database/crypto_billionairs.db\")\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_forest(X_train, X_test, y_train, y_test, table, db_connection):\n",
    "    \n",
    "    clf = RandomForestClassifier(criterion=\"entropy\", min_samples_split= 0.01, min_samples_leaf= 0.005, max_depth=10, class_weight=\"balanced_subsample\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    #print(X_test.head())\n",
    "    X_test_normalized = X_test.copy()\n",
    "    X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "    y_pred = clf.predict(X_test_normalized)\n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([X_test])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    df.to_sql(f\"{table}_rf\", db_connection, if_exists=\"replace\")\n",
    "    return \"random forest\", f1score, f1score_macro, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_knn(X_train, X_test, y_train, y_test, table, db_connection):\n",
    "    \n",
    "    neigh = KNeighborsClassifier(weights=\"uniform\", n_neighbors=3, algorithm=\"ball_tree\")\n",
    "    neigh.fit(X_train, y_train)\n",
    "    \n",
    "    X_test_normalized = X_test.copy()\n",
    "    X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "    y_pred = neigh.predict(X_test_normalized)\n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([X_test])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    df.to_sql(f\"{table}_knn\", db_connection, if_exists=\"replace\")\n",
    "    \n",
    "    return \"k-nearest neighbour\", f1score, f1score_macro, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_support_vector_machine(X_train, X_test, y_train, y_test, table, db_connection):\n",
    "    \n",
    "    svc = SVC(kernel=\"poly\", degree=4, C=1)\n",
    "    svc.fit(X_train, y_train)\n",
    "    \n",
    "    X_test_normalized = X_test.copy()\n",
    "    X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "    y_pred = svc.predict(X_test)\n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([X_test])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    df.to_sql(f\"{table}_svc\", db_connection, if_exists=\"replace\")\n",
    "    \n",
    "    return \"support vector classifier\", f1score, f1score_macro, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mlp(X_train, X_test, y_train, y_test, table, db_connection):\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10), activation=\"tanh\", solver=\"lbfgs\", learning_rate=\"constant\", learning_rate_init=2e-5, tol=1e-5)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    X_test_normalized = X_test.copy()\n",
    "    X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "    y_pred = mlp.predict(X_test_normalized)\n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([X_test])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    df.to_sql(f\"{table}_mlp\", db_connection, if_exists=\"replace\")\n",
    "    \n",
    "    return \"mlp classifier\", f1score, f1score_macro, precision, recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_logistic_regression(X_train, X_test, y_train, y_test, table, db_connection):\n",
    "    \n",
    "    lg = LogisticRegression(solver=\"liblinear\", penalty=\"l1\", C=1)\n",
    "    lg.fit(X_train, y_train)\n",
    "    \n",
    "    X_test_normalized = X_test.copy()\n",
    "    X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "    \n",
    "    y_pred = lg.predict(X_test_normalized)\n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([X_test])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    df.to_sql(f\"{table}_lr\", db_connection, if_exists=\"replace\")\n",
    "    \n",
    "    return \"logistic regression\", f1score, f1score_macro, recall, precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ml_algorithms(db_connection):\n",
    "    \n",
    "    df_ml = pd.DataFrame(columns = range(6))\n",
    "    df_ml.columns = [\"table_name\", \"model\", \"f1-score weighted\", \"f1-score macro\", \"recall macro\", \"precision macro\"]\n",
    "    \n",
    "    table_names = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\", db_connection)\n",
    "    \n",
    "    table_names_list = table_names['name'].tolist()\n",
    "\n",
    "    filtered_table_names = [name for name in table_names_list if \"_1day_features\" in name and 'trades' not in name and not 'equity_curve' in name and '_pooling' not in name]\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    print(filtered_table_names)\n",
    "    for table in filtered_table_names:\n",
    "        \n",
    "        df_temp = pd.read_sql_query(f\"select * from {table}\", db_connection)\n",
    "    \n",
    "        y = df_temp[\"buy_indicator\"] + df_temp[\"short_indicator\"]\n",
    "        y = y.fillna(0)\n",
    "        y = y.astype(str)\n",
    "        \n",
    "        X = df_temp.drop([\"return\", \"buy_indicator\", \"short_indicator\", \"close_buy_indicator\", \"close_short_indicator\", \"time\", \"index\"], axis=1)\n",
    "        \n",
    "        X_train = X.iloc[:-365]\n",
    "        print(table)\n",
    "        X_train[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_train[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "        \n",
    "        X_test = X.iloc[-365:]\n",
    "        \n",
    "        y_train = y.iloc[:-365]\n",
    "        y_test = y.iloc[-365:]\n",
    "        \n",
    "        X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision  = apply_random_forest(X_resampled, X_test, y_resampled, y_test, table[:4] ,db_connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision = apply_knn(X_resampled, X_test, y_resampled, y_test, table[:4] ,db_connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision = apply_support_vector_machine(X_resampled, X_test, y_resampled, y_test, table[:4] ,db_connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision = apply_mlp(X_resampled, X_test, y_resampled, y_test, table[:4] ,db_connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision = apply_logistic_regression(X_resampled, X_test, y_resampled, y_test, table[:4] ,db_connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "    return df_ml\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "df_ml = apply_ml_algorithms(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>model</th>\n",
       "      <th>f1-score weighted</th>\n",
       "      <th>f1-score macro</th>\n",
       "      <th>recall macro</th>\n",
       "      <th>precision macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.434613</td>\n",
       "      <td>0.306404</td>\n",
       "      <td>0.369069</td>\n",
       "      <td>0.394230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>k-nearest neighbour</td>\n",
       "      <td>0.180962</td>\n",
       "      <td>0.150563</td>\n",
       "      <td>0.366187</td>\n",
       "      <td>0.283912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>support vector classifier</td>\n",
       "      <td>0.195157</td>\n",
       "      <td>0.176035</td>\n",
       "      <td>0.314289</td>\n",
       "      <td>0.308376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>mlp classifier</td>\n",
       "      <td>0.036822</td>\n",
       "      <td>0.084530</td>\n",
       "      <td>0.048402</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.606267</td>\n",
       "      <td>0.355632</td>\n",
       "      <td>0.353440</td>\n",
       "      <td>0.383783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.670199</td>\n",
       "      <td>0.436679</td>\n",
       "      <td>0.454135</td>\n",
       "      <td>0.429374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>k-nearest neighbour</td>\n",
       "      <td>0.677228</td>\n",
       "      <td>0.291152</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.258447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>support vector classifier</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>0.064356</td>\n",
       "      <td>0.035813</td>\n",
       "      <td>0.317073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>mlp classifier</td>\n",
       "      <td>0.405566</td>\n",
       "      <td>0.208565</td>\n",
       "      <td>0.261103</td>\n",
       "      <td>0.252693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.675234</td>\n",
       "      <td>0.301473</td>\n",
       "      <td>0.333218</td>\n",
       "      <td>0.292488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            table_name  \\\n",
       "0    ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "1    ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "2    ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "3    ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "4    ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "..                                                 ...   \n",
       "120  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "121  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "122  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "123  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "124  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "\n",
       "                         model  f1-score weighted  f1-score macro  \\\n",
       "0                random forest           0.434613        0.306404   \n",
       "1          k-nearest neighbour           0.180962        0.150563   \n",
       "2    support vector classifier           0.195157        0.176035   \n",
       "3               mlp classifier           0.036822        0.084530   \n",
       "4          logistic regression           0.606267        0.355632   \n",
       "..                         ...                ...             ...   \n",
       "120              random forest           0.670199        0.436679   \n",
       "121        k-nearest neighbour           0.677228        0.291152   \n",
       "122  support vector classifier           0.021687        0.064356   \n",
       "123             mlp classifier           0.405566        0.208565   \n",
       "124        logistic regression           0.675234        0.301473   \n",
       "\n",
       "     recall macro  precision macro  \n",
       "0        0.369069         0.394230  \n",
       "1        0.366187         0.283912  \n",
       "2        0.314289         0.308376  \n",
       "3        0.048402         0.333333  \n",
       "4        0.353440         0.383783  \n",
       "..            ...              ...  \n",
       "120      0.454135         0.429374  \n",
       "121      0.333333         0.258447  \n",
       "122      0.035813         0.317073  \n",
       "123      0.261103         0.252693  \n",
       "124      0.333218         0.292488  \n",
       "\n",
       "[125 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score weighted</th>\n",
       "      <th>f1-score macro</th>\n",
       "      <th>recall macro</th>\n",
       "      <th>precision macro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k-nearest neighbour</th>\n",
       "      <td>0.495017</td>\n",
       "      <td>0.279261</td>\n",
       "      <td>0.330234</td>\n",
       "      <td>0.337764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.345094</td>\n",
       "      <td>0.242474</td>\n",
       "      <td>0.354005</td>\n",
       "      <td>0.342169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp classifier</th>\n",
       "      <td>0.308326</td>\n",
       "      <td>0.190413</td>\n",
       "      <td>0.251180</td>\n",
       "      <td>0.331732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.564501</td>\n",
       "      <td>0.343584</td>\n",
       "      <td>0.371608</td>\n",
       "      <td>0.367727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support vector classifier</th>\n",
       "      <td>0.305066</td>\n",
       "      <td>0.210840</td>\n",
       "      <td>0.284053</td>\n",
       "      <td>0.342252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           f1-score weighted  f1-score macro  recall macro  \\\n",
       "model                                                                        \n",
       "k-nearest neighbour                 0.495017        0.279261      0.330234   \n",
       "logistic regression                 0.345094        0.242474      0.354005   \n",
       "mlp classifier                      0.308326        0.190413      0.251180   \n",
       "random forest                       0.564501        0.343584      0.371608   \n",
       "support vector classifier           0.305066        0.210840      0.284053   \n",
       "\n",
       "                           precision macro  \n",
       "model                                       \n",
       "k-nearest neighbour               0.337764  \n",
       "logistic regression               0.342169  \n",
       "mlp classifier                    0.331732  \n",
       "random forest                     0.367727  \n",
       "support vector classifier         0.342252  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.groupby(df_ml[\"model\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf7c0b8ed4c815043e48994c1e64c08f9d96fdc49c73ce762547f36d7ce0a11b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
