{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_storage import create_connection\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = create_connection(\"../database/crypto_billionairs.db\")\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_random_forest(X_train, X_test, y_train, y_test, table, db_connection):\n",
    "    \n",
    "    clf = RandomForestClassifier(criterion=\"entropy\", min_samples_split= 0.01, min_samples_leaf= 0.005, max_depth=10, class_weight=\"balanced_subsample\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    #print(X_test.head())\n",
    "    X_test_normalized = X_test.copy()\n",
    "    X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "    y_pred = clf.predict(X_test_normalized)\n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([X_test])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    df.to_sql(f\"{table}_random_forest\", db_connection, if_exists=\"replace\")\n",
    "    return \"random forest\", f1score, f1score_macro, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_knn(X_train, X_test, y_train, y_test, table, db_connection):\n",
    "    \n",
    "    neigh = KNeighborsClassifier(weights=\"uniform\", n_neighbors=3, algorithm=\"ball_tree\")\n",
    "    neigh.fit(X_train, y_train)\n",
    "    \n",
    "    X_test_normalized = X_test.copy()\n",
    "    X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "    y_pred = neigh.predict(X_test_normalized)\n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([X_test])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    df.to_sql(f\"{table}_knn\", db_connection, if_exists=\"replace\")\n",
    "    \n",
    "    return \"k-nearest neighbour\", f1score, f1score_macro, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_support_vector_machine(X_train, X_test, y_train, y_test, table, db_connection):\n",
    "    \n",
    "    svc = SVC(kernel=\"poly\", degree=4, C=1)\n",
    "    svc.fit(X_train, y_train)\n",
    "    \n",
    "    X_test_normalized = X_test.copy()\n",
    "    X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "    y_pred = svc.predict(X_test)\n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([X_test])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    df.to_sql(f\"{table}_svc\", db_connection, if_exists=\"replace\")\n",
    "    \n",
    "    return \"support vector classifier\", f1score, f1score_macro, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mlp(X_train, X_test, y_train, y_test, table, db_connection):\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10), activation=\"tanh\", solver=\"lbfgs\", learning_rate=\"constant\", learning_rate_init=2e-5, tol=1e-5)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    X_test_normalized = X_test.copy()\n",
    "    X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "    y_pred = mlp.predict(X_test_normalized)\n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([X_test])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    df.to_sql(f\"{table}_mlp\", db_connection, if_exists=\"replace\")\n",
    "    \n",
    "    return \"mlp classifier\", f1score, f1score_macro, precision, recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_logistic_regression(X_train, X_test, y_train, y_test, table, db_connection):\n",
    "    \n",
    "    lg = LogisticRegression(solver=\"liblinear\", penalty=\"l1\", C=1)\n",
    "    lg.fit(X_train, y_train)\n",
    "    \n",
    "    X_test_normalized = X_test.copy()\n",
    "    X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_test_normalized[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "    \n",
    "    y_pred = lg.predict(X_test_normalized)\n",
    "    f1score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1score_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    y_pred = y_pred.tolist()\n",
    "    df = pd.concat([X_test])\n",
    "    df[\"buy_short_indicator\"] = y_pred\n",
    "    df['close_buy_short_indicator'] = df[\"buy_short_indicator\"].shift(1).fillna(0.0)\n",
    "    df.to_sql(f\"{table}_logistic_regression\", db_connection, if_exists=\"replace\")\n",
    "    \n",
    "    return \"logistic regression\", f1score, f1score_macro, recall, precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ml_algorithms(db_connection):\n",
    "    \n",
    "    df_ml = pd.DataFrame(columns = range(6))\n",
    "    df_ml.columns = [\"table_name\", \"model\", \"f1-score weighted\", \"f1-score macro\", \"recall macro\", \"precision macro\"]\n",
    "    \n",
    "    table_names = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\", db_connection)\n",
    "    \n",
    "    table_names_list = table_names['name'].tolist()\n",
    "\n",
    "    filtered_table_names = [name for name in table_names_list if \"_1day_features\" in name and 'trades' not in name and not 'equity_curve' in name and '_pooling' not in name]\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    print(filtered_table_names)\n",
    "    for table in filtered_table_names:\n",
    "        \n",
    "        df_temp = pd.read_sql_query(f\"select * from {table}\", db_connection)\n",
    "    \n",
    "        y = df_temp[\"buy_indicator\"] + df_temp[\"short_indicator\"]\n",
    "        y = y.fillna(0)\n",
    "        y = y.astype(str)\n",
    "        \n",
    "        X = df_temp.drop([\"return\", \"buy_indicator\", \"short_indicator\", \"close_buy_indicator\", \"close_short_indicator\", \"time\", \"index\"], axis=1)\n",
    "        \n",
    "        X_train = X.iloc[:-365]\n",
    "        print(table)\n",
    "        X_train[[\"open\", \"close\", \"high\", \"low\", \"volume\"]] = scaler.fit_transform(X_train[[\"open\", \"close\", \"high\", \"low\", \"volume\"]])\n",
    "        \n",
    "        X_test = X.iloc[-365:]\n",
    "        \n",
    "        y_train = y.iloc[:-365]\n",
    "        y_test = y.iloc[-365:]\n",
    "        \n",
    "        X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision  = apply_random_forest(X_resampled, X_test, y_resampled, y_test, table[:4] ,db_connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision = apply_knn(X_resampled, X_test, y_resampled, y_test, table[:4] ,db_connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision = apply_support_vector_machine(X_resampled, X_test, y_resampled, y_test, table[:4] ,db_connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision = apply_mlp(X_resampled, X_test, y_resampled, y_test, table[:4] ,db_connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "        string, score, f1score_macro, recall, precision = apply_logistic_regression(X_resampled, X_test, y_resampled, y_test, table[:4] ,db_connection)\n",
    "        df_ml.loc[len(df_ml)] = [table, string, score, f1score_macro, recall, precision]\n",
    "        \n",
    "    return df_ml\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "df_ml = apply_ml_algorithms(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>model</th>\n",
       "      <th>f1-score weighted</th>\n",
       "      <th>f1-score macro</th>\n",
       "      <th>recall macro</th>\n",
       "      <th>precision macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.509773</td>\n",
       "      <td>0.330682</td>\n",
       "      <td>0.341452</td>\n",
       "      <td>0.354525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>k-nearest neighbour</td>\n",
       "      <td>0.165795</td>\n",
       "      <td>0.143807</td>\n",
       "      <td>0.361595</td>\n",
       "      <td>0.292505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>support vector classifier</td>\n",
       "      <td>0.530515</td>\n",
       "      <td>0.368213</td>\n",
       "      <td>0.387322</td>\n",
       "      <td>0.391644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>mlp classifier</td>\n",
       "      <td>0.038134</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.049315</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADA_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.619459</td>\n",
       "      <td>0.361168</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.398165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.567557</td>\n",
       "      <td>0.371240</td>\n",
       "      <td>0.422273</td>\n",
       "      <td>0.389065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>k-nearest neighbour</td>\n",
       "      <td>0.680972</td>\n",
       "      <td>0.291731</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.259361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>support vector classifier</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.061360</td>\n",
       "      <td>0.033976</td>\n",
       "      <td>0.316239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>mlp classifier</td>\n",
       "      <td>0.079406</td>\n",
       "      <td>0.102546</td>\n",
       "      <td>0.295960</td>\n",
       "      <td>0.290736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>TRX_1min_complete_1day_preprocessed_1day_features</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.681935</td>\n",
       "      <td>0.303505</td>\n",
       "      <td>0.335401</td>\n",
       "      <td>0.302171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            table_name  \\\n",
       "0    ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "1    ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "2    ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "3    ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "4    ADA_1min_complete_1day_preprocessed_1day_features   \n",
       "..                                                 ...   \n",
       "135  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "136  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "137  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "138  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "139  TRX_1min_complete_1day_preprocessed_1day_features   \n",
       "\n",
       "                         model  f1-score weighted  f1-score macro  \\\n",
       "0                random forest           0.509773        0.330682   \n",
       "1          k-nearest neighbour           0.165795        0.143807   \n",
       "2    support vector classifier           0.530515        0.368213   \n",
       "3               mlp classifier           0.038134        0.085919   \n",
       "4          logistic regression           0.619459        0.361168   \n",
       "..                         ...                ...             ...   \n",
       "135              random forest           0.567557        0.371240   \n",
       "136        k-nearest neighbour           0.680972        0.291731   \n",
       "137  support vector classifier           0.019669        0.061360   \n",
       "138             mlp classifier           0.079406        0.102546   \n",
       "139        logistic regression           0.681935        0.303505   \n",
       "\n",
       "     recall macro  precision macro  \n",
       "0        0.341452         0.354525  \n",
       "1        0.361595         0.292505  \n",
       "2        0.387322         0.391644  \n",
       "3        0.049315         0.333333  \n",
       "4        0.362699         0.398165  \n",
       "..            ...              ...  \n",
       "135      0.422273         0.389065  \n",
       "136      0.333333         0.259361  \n",
       "137      0.033976         0.316239  \n",
       "138      0.295960         0.290736  \n",
       "139      0.335401         0.302171  \n",
       "\n",
       "[140 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf7c0b8ed4c815043e48994c1e64c08f9d96fdc49c73ce762547f36d7ce0a11b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
